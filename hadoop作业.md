二，思考题

1.  思考hive数据仓库在Hadoop中起到的作用是什么？

    答：（1）hive是建立在Hadoop之上的一种数据仓库基础架构，可以用来存储，查询和分析存储在Hadoop中的大规模数据。它提供了一系列的工具，可以用来进行数据的提取，转化及加载（ETL）。Hive定义了简单的类SQL 查询语言 称为HQL，它允许熟悉 SQL 的用户查询数据。 这个语言也允许熟悉MapReduce的开发者开发自定义的Mapper和 Reduce，以处理内建的Mapper和Reduce无法完成的复杂的分析工作。

    （2）Hive 没有专门的数据格式，可以很好地工作在 Thrift之上，控制分隔符，也允许用户指定数据格式。

    （3）Hive在加载数据过程中不会对数据进行任何的修改 ，只是将数据移动到HDFS中Hive设定的目录下，因此，Hive不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。

1.  简述hive清洗数据清洗的特点。

答：数据清洗的任务是过滤那些不符合要求的数据， 不符合要求的数据主要有不完整的数据、错误的数据及重复的数据3大类。

（1）．不完整的数据:这一类数据主要是一些应该有的信息缺失 对于这一类数据过滤出来,按缺失的内容分别写人不同Excel文件向客户提交,要 在规定的时间内补全。补全后才写人数据仓库。

（2）．错误的数据：业务系统不够健全，在接收输入后没有进行判断直接写人后台数据库造成的， 对于类似于全角字符据前后有不可见字符的问题，只能通过写QL句的方式出来，然后要求客户在业务系统修正之后抽取。日期格式不正确的或者是日期越界的这一类错误会导致ETL运行失败，这一类错误需要去业务系统数据库用SQL的方式挑出来，交给业务主管部门要求限期修正，修正之后再抽取。

（3）.重复的数据:对于这一类数据-- 是维表中会出现这种情况--将重复数据记录的所有字段导出来，让客户确认并整理。对于是否过滤，是否修正一般要求客户确认，对于过滤掉的数据，写入Excel文件或者将过滤数据写入数据表，在ETL开发的初期可以每天向业务单位发送过滤数据的邮件，促使他们尽快地修正错误，同时也可以作为将来验证数据的依据。

3.hive元数据库是用来做是什么的，主要存储什么信息？

答：本质上只是用来存储hive中有哪些数据库，哪些表，表的模式，目录，分区，索引以及命名空间。为数据库创建的目录一般在hive数据仓库目录下。
